{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP8240 : Project Group K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Collecting Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up Access to Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys = {\n",
    "  'consumer_key': '7UmkNb6j9Fv8MdckV9kcmpWex',\n",
    "  'consumer_secret': '6fDqb0S670vgNktrMLS3awceMqGCDMn2dXxkRYhNOZ04YJ63vz',\n",
    "  'access_token_key': '1299904370494992384-0XzXQq55hgrxZ3mlUAKqgP5e5N6Gx8',\n",
    "  'access_token_secret': '2SXqY97u8bT1Q91rLvZUwmS3GvsNkdtBhgn7iQ8xNuDal'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup access to API\n",
    "auth = tweepy.OAuthHandler(twitter_keys['consumer_key'],twitter_keys['consumer_secret'])\n",
    "auth.set_access_token(twitter_keys['access_token_key'],twitter_keys['access_token_secret'])\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK.\n"
     ]
    }
   ],
   "source": [
    "#  Testing the authentication.\n",
    "try:\n",
    "  user = api.verify_credentials()\n",
    "  print('Authentication OK.')\n",
    "except:\n",
    "  print('Error during authentication.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the user is: Vikram Rajan.\n",
      "The location of the user is: Macquarie Park, Sydney.\n",
      "The user has 0 followers.\n",
      "The user has 25 friends.\n"
     ]
    }
   ],
   "source": [
    "# The name of the user.\n",
    "print('The name of the user is: ' + str(user.name) + '.')\n",
    "# The location of the user.\n",
    "print('The location of the user is: ' + str(user.location) + '.')\n",
    "# The number of followers this user has.\n",
    "print('The user has ' + str(user.followers_count) + ' followers.')\n",
    "# The number of friends who this user has.\n",
    "print('The user has ' + str(user.friends_count) + ' friends.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data is collected with the help of api.search function of twitter. \n",
    "Search is made based on 20 most similar words based on original work and around 50 tweets for each tweet is queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to hit API and writing to Dataframe\n",
    "def keywordSearch(ls):\n",
    "    date_since = \"2020-01-01\"\n",
    "    newTweets =[]\n",
    "    for word in ls:\n",
    "        new_search = word + \" -filter:retweets\"\n",
    "        twts = tweepy.Cursor(api.search,\n",
    "                           q=new_search,\n",
    "                           lang=\"en\",\n",
    "                           since=date_since).items(50)\n",
    "        for t in twts:\n",
    "            x={}\n",
    "            x['id'] =  t.id\n",
    "            x['text'] =  t.text\n",
    "            newTweets.append(x)\n",
    "    ndf = pd.DataFrame(newTweets)\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function call with 20 words and the result to be stored in an excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls =[\"islam\",\"bitches\",\"feminists\",\"trans+woman\",\"gay\",\"dwarf\",\"sluts\",\"\",\"negro\",\"nigga\",\"asians\",\"france+muslim\",\"chinese+virus\",\"terrorist\",\"slave\",\"jews\",\"murderer\",\"blonde\",\"taliban\",\"whites\"]\n",
    "#ls = [\"dwarf\"]\n",
    "newTwtsDf =keywordSearch(ls)\n",
    "newTwtsDf.index += 1 \n",
    "newTwtsDf.to_csv('newtweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1324187087436832768</td>\n",
       "      <td>@JaskaranS_ Lol, too powerless and irrelevant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1324187076733095936</td>\n",
       "      <td>Islam didn't steal and killing, it invented \"w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1324186992788164609</td>\n",
       "      <td>@hhhggjjhhg Ashraf will even say it is Islamop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1324186949503066113</td>\n",
       "      <td>idk what is goin to happen in the future but i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1324186945363210242</td>\n",
       "      <td>if you don't know about the rule of Islam then...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text\n",
       "1  1324187087436832768  @JaskaranS_ Lol, too powerless and irrelevant ...\n",
       "2  1324187076733095936  Islam didn't steal and killing, it invented \"w...\n",
       "3  1324186992788164609  @hhhggjjhhg Ashraf will even say it is Islamop...\n",
       "4  1324186949503066113  idk what is goin to happen in the future but i...\n",
       "5  1324186945363210242  if you don't know about the rule of Islam then..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTwtsDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The csv generated above is again further processed in excel for manual annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Collecting Orginal Data\n",
    "\n",
    "Source data can be downloaded from https://github.com/zeerakw/hatespeech. It contains tweet id's and corresponding annotations where tweets are labelled as either Racist, Sexist or Neither Racist or Sexist.\n",
    "\n",
    "Twitter API(statuses_lookup) was used to retrieve the tweets using given tweet IDs and some basic processing was done as required by the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572342978255048705</td>\n",
       "      <td>racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>572341498827522049</td>\n",
       "      <td>racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>572340476503724032</td>\n",
       "      <td>racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572334712804384768</td>\n",
       "      <td>racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>572332655397629952</td>\n",
       "      <td>racism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetID   label\n",
       "0  572342978255048705  racism\n",
       "1  572341498827522049  racism\n",
       "2  572340476503724032  racism\n",
       "3  572334712804384768  racism\n",
       "4  572332655397629952  racism"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'C:/Users/Owner/Downloads/source4.xlsx'\n",
    "#df = pd.read_csv('C:/Users/Owner/Downloads/source4.xlsx')\n",
    "df = pd.read_excel(file_name, sheet_name = \"Sheet2\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Total dataset from source: 17005 \n",
      "Lenth of Racism annotated data: 2068 \n",
      "Lenth of Sexism annotated data: 3378 \n",
      "Lenth of Neither annotated data: 11559\n"
     ]
    }
   ],
   "source": [
    "racismdf=df[df['label']==\"racism\"]\n",
    "sexismdf=df[df['label']==\"sexism\"]\n",
    "neitherdf=df[df['label']==\"none\"]\n",
    "#neitherdf=df[df['label']==\"neither\"]\n",
    "\n",
    "print(\"Length of Total dataset from source:\",len(racismdf) +len(sexismdf)+len(neitherdf),\n",
    "      \"\\nLenth of Racism annotated data:\",len(racismdf),\n",
    "      \"\\nLenth of Sexism annotated data:\",len(sexismdf),\n",
    "      \"\\nLenth of Neither annotated data:\",len(neitherdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function defined to lookup the tweets for given tweet IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_tweets(tweet_IDs, api):\n",
    "    full_tweets = []\n",
    "    tweet_count = len(tweet_IDs)\n",
    "    try:\n",
    "        for i in range(int(tweet_count / 100) + 1):\n",
    "            end_loc = min((i + 1) * 100, tweet_count)\n",
    "            x =tweet_IDs[i * 100:end_loc]\n",
    "            full_tweets.extend(\n",
    "                api.statuses_lookup(tweet_IDs[i * 100:end_loc])\n",
    "            )\n",
    "        return full_tweets\n",
    "    except tweepy.TweepError:\n",
    "        print('Something went wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettweets(daf):\n",
    "    good_tweet_ids = [i for i in daf.tweetID] #tweet ids to look up \n",
    "    results = lookup_tweets(good_tweet_ids, api) #apply function\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweet IDs for Racism after lookup is: 77 out of  2068\n",
      "Total tweet IDs for Sexism after lookup is: 2777 out of  3378\n",
      "Total tweet IDs for Neither after lookup is: 7797 out of  11559\n"
     ]
    }
   ],
   "source": [
    "#for racism\n",
    "racism_results = gettweets(racismdf)\n",
    "print(\"Total tweet IDs for Racism after lookup is:\",len(racism_results),\"out of \",len(racismdf))\n",
    "sexism_results = gettweets(sexismdf)\n",
    "print(\"Total tweet IDs for Sexism after lookup is:\",len(sexism_results),\"out of \",len(sexismdf))\n",
    "neither_results = gettweets(neitherdf)\n",
    "print(\"Total tweet IDs for Neither after lookup is:\",len(neither_results),\"out of \",len(neitherdf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to write the results to json files as required by the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeResultsToJSON(tweets,screen_name):    \n",
    "    listOfTweets = []\n",
    "    for json_tweet in tweets:\n",
    "        x={}\n",
    "        t = json_tweet._json\n",
    "        x['id'] =  t['id']\n",
    "        x['text'] =  t['text']\n",
    "        x['user'] ={}\n",
    "        x['user']['name'] =  t['user']['name']\n",
    "        x['Annotation'] =  screen_name\n",
    "        listOfTweets.append(x)\n",
    "    with open(screen_name +'.json', mode = 'w') as file:\n",
    "        file.write(json.dumps(listOfTweets, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing to JSON\n",
    "writeResultsToJSON(racism_results,\"racism\")  \n",
    "writeResultsToJSON(sexism_results,\"sexism\")\n",
    "writeResultsToJSON(neither_results,\"neither\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************************End Of Data Collection********************************************************."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
